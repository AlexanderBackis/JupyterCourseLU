{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Neutron Spectroscopy at SEQOUIA using the Multi-Grid</center></h1>\n",
    "<table><tr><td><img src='Figs/preparing.jpeg' height=\"400\" width=\"400\"><figcaption>Fig.1 - Ensembling of Multi-Grid MG.SEQ prototype.</figcaption></td><td><img src='Figs/SNS.png' height=\"400\" width=\"400\"><figcaption>Fig.2 - Multi-Grid in the SEQOUIA instrument at SNS.</figcaption></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The current notebook presents a summary of the results from the data analysis performed\n",
    "on data collected during measurements at the Spallation Neutron Source (SNS) in Oak Ridge National Laboratory, USA, between August and September 2018. The SEQOUIA instrument, a fine-resolution Fermi chopper Spectrometer, was used and the Multi-Grid was incorporated as neutron detector. The purpose was to charactherise the detector performance. The properties that were examined, to name a few, consisted of energy resolution, efficiency and count rate. To test these properties five different sample where used: Vanadium, Silicon (powder and crystal), Water, US and C$_4$H$_2$I$_2$S.\n",
    "\n",
    "First, the inital data processing and clustering of neutron events will be presented. After that, the results from measurements on each element will be presented and discussed. Since the code used to perform this analysis is large, not all parts will be included in this notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary packages\n",
    "We start by importing all the packages we will need to perform our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import struct\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly as py\n",
    "import seaborn as sns\n",
    "import plotly.graph_objs as go\n",
    "import matplotlib.pyplot as plt\n",
    "from plot import get_detectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and clustering measurement file\n",
    "Our next step is to read the data gathered at SNS. After the data has been read, it must be clustered into neutron events and saved in a convenient fashion. This is done using the pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(file_path):\n",
    "    \"\"\" Imports '.mesytec'-file from 'file_path'. Does this in three steps:\n",
    "            \n",
    "            1. Reads file as binary and saves data in 'content'\n",
    "            2. Finds the end of the configuration text, i.e. '}\\n}\\n' followed\n",
    "               by 0 to n spaces, then saves everything after this to \n",
    "               'reduced_content'.\n",
    "            3. Groups data into 'uint'-words of 4 bytes (32 bits) length\n",
    "        \n",
    "    Args:\n",
    "        file_path (str): Name of '.mesytec'-file that contains the data\n",
    "            \n",
    "    Returns:\n",
    "        data (tuple): A tuple where each element is a 32 bit mesytec word\n",
    "            \n",
    "    \"\"\"    \n",
    "    with open(file_path, mode='rb') as bin_file:\n",
    "        piece_size = 1e3\n",
    "        content = bin_file.read(piece_size * (1 << 20))\n",
    "        # Skip configuration text\n",
    "        match = re.search(b'}\\n}\\n[ ]*', content)\n",
    "        start = match.end()\n",
    "        content = content[start:]\n",
    "        data = struct.unpack('I' * (len(content)//4), content)\n",
    "        # Import data\n",
    "        moreData = True\n",
    "        imported_data = piece_size\n",
    "        while moreData:\n",
    "            imported_data += piece_size\n",
    "            piece = bin_file.read(piece_size * (1 << 20))\n",
    "            if not piece:  # Reached end of file\n",
    "                moreData = False\n",
    "            else:\n",
    "                data += struct.unpack('I' * (len(piece)//4), piece)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering data\n",
    "The next step is to iterate through the data file and form 'Candidate Neutron Events'. To do this, it first necessary to understand the format of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======    MASKS    ======= #\n",
    "TypeMask      =   0xC0000000     # 1100 0000 0000 0000 0000 0000 0000 0000\n",
    "DataMask      =   0xF0000000     # 1111 0000 0000 0000 0000 0000 0000 0000\n",
    "\n",
    "ChannelMask   =   0x00FFF000     # 0000 0000 1111 1111 1111 0000 0000 0000\n",
    "BusMask       =   0x0F000000     # 0000 1111 0000 0000 0000 0000 0000 0000\n",
    "ADCMask       =   0x00000FFF     # 0000 0000 0000 0000 0000 1111 1111 1111\n",
    "TimeStampMask =   0x3FFFFFFF     # 0011 1111 1111 1111 1111 1111 1111 1111\n",
    "NbrWordsMask  =   0x00000FFF     # 0000 0000 0000 0000 0000 1111 1111 1111\n",
    "GateStartMask =   0x0000FFFF     # 0000 0000 0000 0000 1111 1111 1111 1111\n",
    "ExTsMask      =   0x0000FFFF     # 0000 0000 0000 0000 1111 1111 1111 1111\n",
    "TriggerMask   =   0xCF000000     # 1100 1111 0000 0000 0000 0000 0000 0000\n",
    "\n",
    "\n",
    "# =======  DICTONARY  ======= #\n",
    "Header        =   0x40000000     # 0100 0000 0000 0000 0000 0000 0000 0000\n",
    "Data          =   0x00000000     # 0000 0000 0000 0000 0000 0000 0000 0000\n",
    "EoE           =   0xC0000000     # 1100 0000 0000 0000 0000 0000 0000 0000\n",
    "\n",
    "DataBusStart  =   0x30000000     # 0011 0000 0000 0000 0000 0000 0000 0000\n",
    "DataEvent     =   0x10000000     # 0001 0000 0000 0000 0000 0000 0000 0000\n",
    "DataExTs      =   0x20000000     # 0010 0000 0000 0000 0000 0000 0000 0000\n",
    "\n",
    "Trigger       =   0x41000000     # 0100 0001 0000 0000 0000 0000 0000 0000\n",
    "\n",
    "# =======  BIT-SHIFTS  ======= #\n",
    "ChannelShift  =   12\n",
    "BusShift      =   24\n",
    "ExTsShift     =   30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/alexanderbackis/Desktop/Jupyter/project-work-2018-AlexanderBackis/../Tables/Coordinates_MG_SEQ_ESS.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b90ce76cd7f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdetectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_detectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/Jupyter/project-work-2018-AlexanderBackis/plot.py\u001b[0m in \u001b[0;36mget_detectors\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2536\u001b[0m     \u001b[0;31m# Initiate detector mappings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m     \u001b[0mdetector_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_ill_channel_to_coordinate_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2538\u001b[0;31m     \u001b[0mdetector_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_ess_channel_to_coordinate_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2539\u001b[0m     \u001b[0mdetector_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_ess_channel_to_coordinate_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset_3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2540\u001b[0m     \u001b[0mdetector_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdetector_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetector_3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Jupyter/project-work-2018-AlexanderBackis/plot.py\u001b[0m in \u001b[0;36mcreate_ess_channel_to_coordinate_map\u001b[0;34m(theta, offset)\u001b[0m\n\u001b[1;32m   3286\u001b[0m     file_path = os.path.join(dirname, \n\u001b[1;32m   3287\u001b[0m                              '../Tables/Coordinates_MG_SEQ_ESS.xlsx')\n\u001b[0;32m-> 3288\u001b[0;31m     \u001b[0mmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3289\u001b[0m     \u001b[0mcoordinates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m801\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3290\u001b[0m     \u001b[0mess_ch_to_coord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m124\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, **kwds)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     return io.parse(\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, io, **kwds)\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xlrd/__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[0;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# a ZIP file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/alexanderbackis/Desktop/Jupyter/project-work-2018-AlexanderBackis/../Tables/Coordinates_MG_SEQ_ESS.xlsx'"
     ]
    }
   ],
   "source": [
    "detectors = get_detectors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ILL_buses = [0, 1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_data(data, ILL_buses=[]):\n",
    "    \"\"\" Clusters the imported data and stores it two data frames: one for \n",
    "        individual events and one for coicident events (i.e. candidate neutron \n",
    "        events). \n",
    "        \n",
    "        Does this in the following fashion for coincident events: \n",
    "            1. Reads one word at a time\n",
    "            2. Checks what type of word it is (Header, BusStart, DataEvent, \n",
    "               DataExTs or EoE).\n",
    "            3. When a Header is encountered, 'isOpen' is set to 'True',\n",
    "               signifying that a new event has been started. Data is then\n",
    "               gathered into a single coincident event until a different bus is\n",
    "               encountered (unless ILL exception), in which case a new event is\n",
    "               started.\n",
    "            4. When EoE is encountered the event is formed, and timestamp is \n",
    "               assigned to it and all the created events under the current \n",
    "               Header. This event is placed in the created dictionary.\n",
    "            5. After the iteration through data is complete, the dictionary\n",
    "               containing the coincident events is convereted to a DataFrame.  \n",
    "    Args:\n",
    "        data (tuple)    : Tuple containing data, one word per element.\n",
    "        ILL_buses (list): List containg all ILL buses\n",
    "        \n",
    "    Returns:\n",
    "        coincident_events_df (DataFrame): DataFrame containing one neutron\n",
    "                                          event per row. Each neutron event has\n",
    "                                          information about: \"Bus\", \"Time\", \n",
    "                                          \"ToF\", \"wCh\", \"gCh\", \"wADC\", \"gADC\",\n",
    "                                          \"wM\", \"gM\", \"d\".                   \n",
    "    \"\"\"\n",
    "    # Initiate coincident_events dictionary\n",
    "    size = len(data)\n",
    "    coincident_events = {'Bus': np.zeros([size], dtype=int),  # Which bus recorded the event?\n",
    "                         'Time': np.zeros([size], dtype=int), # At what time was it recorded?\n",
    "                         'ToF': np.zeros([size], dtype=int),  # What was the Time-of-Flight?\n",
    "                         'wCh': np.zeros([size], dtype=int),  # Which wire-channel recorded it?\n",
    "                         'gCh': np.zeros([size], dtype=int),  # Which grid-channel recorded it?\n",
    "                         'wADC': np.zeros([size], dtype=int), # How much ADC was collected by wire(s)?\n",
    "                         'gADC': np.zeros([size], dtype=int), # How much ADC was collected by grid(s)?\n",
    "                         'wM': np.zeros([size], dtype=int),   # What was the wire multiplicity?\n",
    "                         'gM': np.zeros([size], dtype=int),   # What was the grid multiplicity?\n",
    "                         'd': np.zeros([size], dtype=float)   # What was the sample-detection distance?\n",
    "                         }\n",
    "    # Declare variables\n",
    "    TriggerTime   =    0\n",
    "    index         =   -1\n",
    "    # Declare temporary variables\n",
    "    isOpen              =    False\n",
    "    isData              =    False\n",
    "    isTrigger           =    False\n",
    "    Bus                 =    -1\n",
    "    previousBus         =    -1\n",
    "    maxADCw             =    0\n",
    "    maxADCg             =    0\n",
    "    nbrCoincidentEvents =    0\n",
    "    Time                =    0\n",
    "    extended_time_stamp =    None\n",
    "    \n",
    "    # Five possibilities in each word: Header, DataBusStart, DataEvent, DataExTs or EoE.\n",
    "    for count, word in enumerate(data):\n",
    "        if (word & TypeMask) == Header:                           \n",
    "            isOpen = True\n",
    "            isTrigger = (word & TriggerMask) == Trigger\n",
    "        \n",
    "        elif ((word & DataMask) == DataBusStart) & isOpen:       \n",
    "            Bus = (word & BusMask) >> BusShift\n",
    "            isData = True\n",
    "            if (previousBus in ILL_buses) and (Bus in ILL_buses):\n",
    "                pass\n",
    "            else:                \n",
    "                previousBus = Bus\n",
    "                maxADCw = 0\n",
    "                maxADCg = 0\n",
    "                nbrCoincidentEvents += 1\n",
    "                index += 1\n",
    "                coincident_events['wCh'][index] = -1\n",
    "                coincident_events['gCh'][index] = -1\n",
    "                coincident_events['Bus'][index] = Bus  \n",
    "        \n",
    "        elif ((word & DataMask) == DataEvent) & isOpen:           \n",
    "            Channel = ((word & ChannelMask) >> ChannelShift)\n",
    "            ADC = (word & ADCMask)\n",
    "            if Channel >= 120:\n",
    "                pass\n",
    "            elif Channel < 80:\n",
    "                coincident_events['Bus'][index] = Bus # Remove if trigger is on wire\n",
    "                coincident_events['wADC'][index] += ADC\n",
    "                coincident_events['wM'][index] += 1\n",
    "                if ADC > maxADCw:\n",
    "                    coincident_events['wCh'][index] = Channel ^ 1 #Shift odd and even Ch\n",
    "                    maxADCw = ADC\n",
    "            else:\n",
    "                coincident_events['gADC'][index] += ADC\n",
    "                coincident_events['gM'][index] += 1\n",
    "                if ADC > maxADCg:\n",
    "                    coincident_events['gCh'][index] = Channel\n",
    "                    maxADCg = ADC\n",
    "        \n",
    "        elif ((word & DataMask) == DataExTs) & isOpen:\n",
    "            extended_time_stamp = (word & ExTsMask) << ExTsShift   \n",
    "        \n",
    "        elif ((word & TypeMask) == EoE) & isOpen:\n",
    "            # Read time\n",
    "            time_stamp = (word & TimeStampMask)\n",
    "            if extended_time_stamp is not None:\n",
    "                Time = extended_time_stamp | time_stamp\n",
    "            else:\n",
    "                Time = time_stamp\n",
    "            \n",
    "            # Update Trigger value\n",
    "            if isTrigger:\n",
    "                TriggerTime = Time                    \n",
    "            \n",
    "            # Assign timestamp and ToF\n",
    "            ToF = Time - TriggerTime\n",
    "            for i in range(0, nbrCoincidentEvents):\n",
    "                coincident_events['Time'][index-i] = Time\n",
    "                coincident_events['ToF'][index-i] = ToF\n",
    "            \n",
    "            #Assign d\n",
    "            for i in range(0, nbrCoincidentEvents):\n",
    "                wCh = coincident_events['wCh'][index-i]\n",
    "                gCh = coincident_events['gCh'][index-i]\n",
    "                if (wCh != 0 and gCh != 0) and (wCh != -1 and gCh != -1):\n",
    "                    eventBus = coincident_events['Bus'][index]\n",
    "                    ToF = coincident_events['ToF'][index-i]\n",
    "                    d = get_d(eventBus, wCh, gCh, detector_vec)\n",
    "                    coincident_events['d'][index-i] = d\n",
    "                else:\n",
    "                    coincident_events['d'][index-i] = -1\n",
    "                \n",
    "            #Reset temporary variables\n",
    "            nbrCoincidentEvents  =  0\n",
    "            Bus                  =  -1\n",
    "            previousBus          =  -1\n",
    "            isOpen               =  False\n",
    "            isData               =  False\n",
    "            isTrigger            =  False\n",
    "            Time                 =  0\n",
    "            \n",
    "    #Remove empty elements and save in DataFrame for easier analysis\n",
    "    for key in coincident_events:\n",
    "        coincident_events[key] = coincident_events[key][0:index]\n",
    "    coincident_events_df = pd.DataFrame(coincident_events)\n",
    "        \n",
    "    return coincident_events_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
